import os
import torch
from torchvision import transforms as T
import numpy as np
import random  # äº‚æ•¸æ§åˆ¶
import argparse  # å‘½ä»¤åˆ—åƒæ•¸è™•ç†
from model_unet import AnomalyDetectionModel # å‡è¨­ AnomalyDetectionModel åŠå…¶å­ç¶²è·¯åœ¨é€™è£¡
import torchvision.transforms as transforms
import cv2
from PIL import Image # é›–ç„¶ transform ç”¨åˆ°äº†ï¼Œä½†ç›´æ¥ç”¨ cv2 è®€å¯«æ›´ä¸€è‡´

def setup_seed(seed):
    # è¨­å®šéš¨æ©Ÿç¨®å­ï¼Œç¢ºä¿å¯¦é©—å¯é‡ç¾
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    np.random.seed(seed)
    random.seed(seed)
    torch.backends.cudnn.deterministic = True  # ä¿è­‰çµæœå¯é‡ç¾
    torch.backends.cudnn.benchmark = False  # é—œé–‰è‡ªå‹•æœ€ä½³åŒ–æœå°‹


# =======================
# Utilities
# =======================
def get_available_gpu():
    """è‡ªå‹•é¸æ“‡è¨˜æ†¶é«”ä½¿ç”¨ç‡æœ€ä½çš„GPU"""
    if not torch.cuda.is_available():
        return -1  # æ²’æœ‰GPUå¯ç”¨

    gpu_count = torch.cuda.device_count()
    if gpu_count == 0:
        return -1

    # æª¢æŸ¥æ¯å€‹GPUçš„è¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³
    gpu_memory = []
    for i in range(gpu_count):
        torch.cuda.set_device(i)
        memory_allocated = torch.cuda.memory_allocated(i)
        # memory_reserved = torch.cuda.memory_reserved(i) # é€™å€‹åœ¨æŸäº›æƒ…æ³ä¸‹æœƒé¡¯ç¤ºè¼ƒé«˜ï¼Œæˆ‘å€‘æ›´é—œæ³¨å·²åˆ†é…çš„
        gpu_memory.append((i, memory_allocated)) # åªç”¨ allocated

    # é¸æ“‡è¨˜æ†¶é«”ä½¿ç”¨æœ€å°‘çš„GPU
    available_gpu = min(gpu_memory, key=lambda x: x[1])[0]
    return available_gpu


def visualize_and_save(original_img_rgb, recon_img_rgb, anomaly_map_normalized, binary_mask,
                       save_path_base):
    """
    å°‡æ¨è«–çµæœå¯è¦–åŒ–ä¸¦å„²å­˜æˆåœ–ç‰‡ã€‚

    Args:
        original_img_rgb (np.ndarray): åŸå§‹è¼¸å…¥å½±åƒ (H, W, 3)ï¼ŒRGBæ ¼å¼ï¼Œå€¼åŸŸ [0, 255]ã€‚
        recon_img_rgb (np.ndarray): é‡å»ºå¾Œçš„å½±åƒ (H, W, 3)ï¼ŒRGBæ ¼å¼ï¼Œå€¼åŸŸ [0, 255]ã€‚
        anomaly_map_normalized (np.ndarray): ç•°å¸¸åˆ†æ•¸åœ– (H, W)ï¼Œå€¼åŸŸ [0, 255]ï¼Œ8-bit æ•´æ•¸ã€‚
        binary_mask (np.ndarray): äºŒå€¼åŒ–çš„ç•°å¸¸é®ç½© (H, W)ï¼Œå€¼ç‚º 0 æˆ– 255ã€‚
        save_path_base (str): å„²å­˜æª”æ¡ˆçš„åŸºç¤è·¯å¾‘èˆ‡æª”å (ä¸å«å‰¯æª”å)ã€‚
    """
    # ç¢ºä¿å„²å­˜ç›®éŒ„å­˜åœ¨
    save_dir = os.path.dirname(save_path_base)
    if not os.path.exists(save_dir):
        os.makedirs(save_dir, exist_ok=True)

    # å°‡ anomaly_map è½‰æ›ç‚ºç†±åŠ›åœ–
    heatmap_color = cv2.applyColorMap(anomaly_map_normalized, cv2.COLORMAP_JET)

    # å°‡ç†±åŠ›åœ–ç–ŠåŠ åˆ°åŸå§‹å½±åƒä¸Š
    # å› ç‚º original_img_rgb æ˜¯ RGBï¼Œè€Œ cv2.addWeighted æœŸæœ› BGRï¼Œæ‰€ä»¥å…ˆè½‰æ›ä¸€ä¸‹
    original_img_bgr = cv2.cvtColor(original_img_rgb, cv2.COLOR_RGB2BGR)
    overlay = cv2.addWeighted(original_img_bgr, 0.6, heatmap_color, 0.4, 0)

    # å°‡äºŒå€¼åŒ–é®ç½©è½‰ç‚ºä¸‰é€šé“ï¼Œæ–¹ä¾¿åˆä½µ (BGC æ ¼å¼)
    binary_mask_color = cv2.cvtColor(binary_mask, cv2.COLOR_GRAY2BGR)

    # å°‡å››å¼µåœ–æ‹¼æ¥æˆä¸€å¼µå¤§åœ– (åŸå§‹åœ– | é‡å»ºåœ– | ç–ŠåŠ ç†±åŠ›åœ– | äºŒå€¼åœ–)
    # ç¢ºä¿æ‰€æœ‰åœ–éƒ½æ˜¯ BGR æ ¼å¼
    combined_img = np.hstack([original_img_bgr, recon_img_rgb, overlay, binary_mask_color])

    # å„²å­˜åˆä½µå¾Œçš„å½±åƒ
    cv2.imwrite(f"{save_path_base}_results.png", combined_img)
    print(f"âœ… çµæœå·²å„²å­˜è‡³: {save_path_base}_results.png")


def run_inference(img_path, model, device, save_path_base, resize_shape=(256, 256)):
    """
    å°å–®å¼µå½±åƒåŸ·è¡Œç•°å¸¸æª¢æ¸¬æ¨è«–ã€‚

    Args:
        img_path (str): è¼¸å…¥å½±åƒçš„è·¯å¾‘ã€‚
        model (nn.Module): è¨“ç·´å¥½çš„å­¸ç”Ÿæ¨¡å‹ã€‚
        device (str): 'cuda' æˆ– 'cpu'ã€‚
        save_path_base (str): å„²å­˜çµæœçš„åŸºç¤è·¯å¾‘èˆ‡æª”åã€‚
        resize_shape (tuple): åœ–åƒç¸®æ”¾çš„ç›®æ¨™å°ºå¯¸ (H, W)ã€‚

    Returns:
        tuple: (anomaly_map, binary_mask)
    """
    # --- 1. å½±åƒé è™•ç† ---
    # å®šç¾©èˆ‡è¨“ç·´æ™‚ç›¸åŒçš„è½‰æ›æµç¨‹
    # æ³¨æ„ï¼šä½ çš„è¨“ç·´é›† MVTecDRAEMTrainDataset ä¸­è®€å–å¾Œæ˜¯ (H, W, C)ï¼Œç„¶å¾Œè½‰ç‚º (C, H, W)
    # ä¸¦æ­¸ä¸€åŒ–åˆ° 0-1ã€‚é€™è£¡çš„æ¨ç†ä¹Ÿè¦ä¿æŒä¸€è‡´ã€‚
    
    original_img_cv = cv2.imread(img_path)
    if original_img_cv is None:
        print(f"âŒ éŒ¯èª¤: ç„¡æ³•è®€å–å½±åƒ {img_path}")
        return None, None
    
    # å°‡ BGR è½‰ç‚º RGBï¼Œå› ç‚ºä½ è¨“ç·´æ™‚ä½¿ç”¨çš„ transform é è¨­æ˜¯ RGB
    original_img_rgb_display = cv2.cvtColor(original_img_cv, cv2.COLOR_BGR2RGB) 
    
    # ç¸®æ”¾å½±åƒ
    original_img_resized = cv2.resize(original_img_rgb_display, dsize=(resize_shape[1], resize_shape[0]))
    
    # æ­¸ä¸€åŒ–ä¸¦è½‰æ›ç‚º Tensor (C, H, W)
    img_tensor = transforms.ToTensor()(original_img_resized).unsqueeze(0).to(device) # (1, 3, H, W)

    # --- 2. åŸ·è¡Œæ¨¡å‹æ¨è«– ---
    with torch.no_grad():
        # ç”±æ–¼ä½ çš„æ¨¡å‹æœŸæœ› 3 é€šé“è¼¸å…¥ï¼Œç›´æ¥å‚³å…¥ img_tensor
        recon_image, seg_map_raw, _ = model(img_tensor, return_feats=True) # ä¿®æ”¹ï¼šæ¨¡å‹ç¾åœ¨è¼¸å‡ºseg_map_rawæ˜¯2é€šé“

    # --- 3. çµæœå¾Œè™•ç† ---
    # å°‡è¼¸å‡ºçš„ logit è½‰æ›ç‚ºæ©Ÿç‡åˆ†ä½ˆ (å¦‚æœä½ çš„æ¨¡å‹è¼¸å‡ºæ˜¯ logits)
    # å¦‚æœä½ çš„æ¨¡å‹æœ€å¾Œä¸€å±¤æ˜¯ sigmoidï¼Œå‰‡å¯èƒ½ä¸éœ€è¦ softmax
    # ä½†ç‚ºäº†é€šç”¨æ€§ï¼Œä½¿ç”¨ softmax è™•ç† 2 é€šé“è¼¸å‡ºæ˜¯å®‰å…¨çš„
    seg_map_softmax = torch.softmax(seg_map_raw, dim=1) 
    
    # å–å‡º "ç•°å¸¸" é¡åˆ¥çš„æ©Ÿç‡åœ– (å‡è¨­é¡åˆ¥ 1 æ˜¯ç•°å¸¸ï¼Œèˆ‡è¨“ç·´æ™‚çš„è™•ç†ä¸€è‡´)
    anomaly_map_tensor = seg_map_softmax[:, 1, :, :] # (B, H, W)

    # å°‡ Tensor è½‰ç‚º NumPy array ä»¥ä¾¿å¾ŒçºŒè™•ç†
    anomaly_map = anomaly_map_tensor.squeeze().cpu().numpy() # (H, W)
    
    # è™•ç†é‡å»ºåœ–åƒ
    recon_image_np = recon_image.squeeze(0).permute(1, 2, 0).cpu().numpy() # (H, W, C)
    recon_image_np = (recon_image_np * 255).astype(np.uint8) # å¾ [0, 1] è½‰å› [0, 255]
    # recon_image_np ç¾åœ¨æ˜¯ RGB æ ¼å¼

    # --- 4. ç”¢ç”ŸäºŒå€¼åŒ–é®ç½© ---
    # è¨­å®šä¸€å€‹é–¾å€¼ï¼Œå°‡ç•°å¸¸æ©Ÿç‡å¤§æ–¼è©²å€¼çš„åƒç´ æ¨™è¨˜ç‚º 1 (ç•°å¸¸)
    threshold = 0.5 # å¯ä»¥æ ¹æ“š P-AUROC çš„æœ€ä½³é–¾å€¼ä¾†èª¿æ•´
    binary_mask = (anomaly_map > threshold).astype(np.uint8) * 255  # è½‰ç‚º 0 æˆ– 255

    # --- 5. å¯è¦–åŒ–ä¸¦å„²å­˜ ---
    visualize_and_save(original_img_resized, recon_image_np, 
                       (anomaly_map * 255).astype(np.uint8), binary_mask, save_path_base)

    return anomaly_map, binary_mask


# =======================
# Main Pipeline
# =======================
def main(obj_names, args):
    setup_seed(111)  # å›ºå®šéš¨æ©Ÿç¨®å­
    device = "cuda" if torch.cuda.is_available() else "cpu"
    # å»ºç«‹ä¸»å­˜æª”è³‡æ–™å¤¾
    save_root = "./inference_results" # æ¨ç†çµæœé€šå¸¸ä¿å­˜åœ¨ä¸åŒçš„ç›®éŒ„
    if not os.path.exists(save_root):
        os.makedirs(save_root)
    print("ğŸ”„ é–‹å§‹æ¸¬è©¦ï¼Œå…±æœ‰ç‰©ä»¶é¡åˆ¥:", len(obj_names))

    # --- æ¨¡å‹åƒæ•¸å®šç¾© (èˆ‡è¨“ç·´æ™‚ä¿æŒä¸€è‡´) ---
    IMG_CHANNELS = 3 # ä½ çš„è¨“ç·´æ—¥èªŒé¡¯ç¤º input_image_val shape: torch.Size([X, 3, 256, 256])
    SEG_CLASSES = 2  # ä½ çš„è¨“ç·´æ—¥èªŒé¡¯ç¤º student_seg_map_val_raw shape: torch.Size([X, 2, 256, 256])
    RECON_BASE = 64  # <-- å‡è¨­èˆ‡ä½ è¨“ç·´æ™‚çš„ recon_base ç›¸åŒ
    DISC_BASE = 64   # <-- å‡è¨­èˆ‡ä½ è¨“ç·´æ™‚çš„ disc_base ç›¸åŒ
    RESIZE_SHAPE = (256, 256) # ç¢ºä¿èˆ‡è¨“ç·´æ™‚ä¿æŒä¸€è‡´

    for obj_name in obj_names:
        print(f"â–¶ï¸æ¸¬è©¦ç‰©ä»¶é¡åˆ¥: {obj_name}")
        
        student_model = AnomalyDetectionModel(
            recon_in=IMG_CHANNELS,
            recon_out=IMG_CHANNELS, # é‡å»ºè¼¸å‡ºé€šå¸¸èˆ‡è¼¸å…¥é€šé“æ•¸ç›¸åŒ
            recon_base=RECON_BASE,
            disc_in=IMG_CHANNELS * 2, # åŸå§‹è¼¸å…¥(3) + é‡å»ºåœ–åƒ(3) = 6é€šé“
            disc_out=SEG_CLASSES,
            disc_base=DISC_BASE
        ).to(device)

        # è¼‰å…¥è¨“ç·´å¥½çš„å­¸ç”Ÿæ¨¡å‹æ¬Šé‡
        # å»ºè­°è¼‰å…¥åŸºæ–¼ AUROC ä¿å­˜çš„æœ€ä½³æ¨¡å‹
        model_weights_path = os.path.join(args.checkpoint_dir, f"{obj_name}_best_auroc.pckl") # â¬…ï¸ ç¢ºä¿é€™è£¡çš„è·¯å¾‘æ­£ç¢º
        if not os.path.exists(model_weights_path):
            print(f"âŒ éŒ¯èª¤: æœªæ‰¾åˆ°æ¨¡å‹æ¬Šé‡æª”æ¡ˆ: {model_weights_path}ï¼Œè«‹æª¢æŸ¥è·¯å¾‘æˆ–è¨“ç·´æ˜¯å¦å®Œæˆã€‚")
            continue
            
        student_model.load_state_dict(
            torch.load(model_weights_path, map_location=device))

        # --- 2. è¨­å®šç‚ºè©•ä¼°æ¨¡å¼ ---
        student_model.eval()

        test_path = os.path.join(args.mvtec_root, obj_name, 'test')  # æ¸¬è©¦è³‡æ–™è·¯å¾‘
        items = ['good', 'broken_large', 'broken_small',
                 'contamination']  # æ¸¬è©¦è³‡æ–™æ¨™ç±¤
        print(f"ğŸ” æ¸¬è©¦è³‡æ–™å¤¾ï¼š{test_path}ï¼Œå…± {len(items)} é¡åˆ¥")

        # ä¾é¡åˆ¥é€å¼µè®€å–å½±åƒä¸¦åŸ·è¡Œæ¨è«–
        for item in items:
            item_path = os.path.join(test_path, item)
            # å»ºç«‹è©²é¡åˆ¥çš„è¼¸å‡ºè³‡æ–™å¤¾
            output_dir = os.path.join(save_root, obj_name, item)
            os.makedirs(output_dir, exist_ok=True)  # ç¢ºä¿è³‡æ–™å¤¾å­˜åœ¨

            if not os.path.exists(item_path):
                print(f"âš ï¸ è­¦å‘Š: è·¯å¾‘ä¸å­˜åœ¨ {item_path}ï¼Œè·³éã€‚")
                continue

            img_files = [
                f for f in os.listdir(item_path)
                if f.endswith('.png') or f.endswith('.jpg')
            ]

            print(f"\nğŸ“‚ é¡åˆ¥ï¼š{item}ï¼Œå…± {len(img_files)} å¼µå½±åƒ")

            for img_name in img_files:
                img_path = os.path.join(item_path, img_name)
                print(f"ğŸ–¼ï¸ è™•ç†å½±åƒï¼š{img_path}")

                # å»æ‰å‰¯æª”åï¼Œåªå–æª”åä¸»é«”
                base_name, _ = os.path.splitext(img_name)
                # è¨­å®šå„²å­˜è·¯å¾‘
                save_path_base = os.path.join(output_dir, base_name)

                # --- åŸ·è¡Œæ¨ç† ---
                anomaly_map, binary_mask = run_inference(
                    img_path, student_model, device, save_path_base, resize_shape=RESIZE_SHAPE)
        print(f"\nâœ… ç‰©ä»¶é¡åˆ¥ {obj_name} æ¸¬è©¦å®Œæˆï¼")
    print("\nğŸ‰ æ‰€æœ‰æ¸¬è©¦å·²å®Œæˆï¼")


# =======================
# Run pipeline
# =======================
if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument('--obj_id', action='store', type=int, required=True)
    parser.add_argument('--gpu_id',
                        action='store',
                        type=int,
                        default=-2,
                        required=False,
                        help='GPU ID (-2: auto-select, -1: CPU)')
    parser.add_argument('--mvtec_root', type=str, default='./mvtec', help='Path to the MVTec dataset root directory')
    parser.add_argument('--checkpoint_dir', type=str, default='./save_files', help='Directory to load model checkpoints')
    
    args = parser.parse_args()

    # è‡ªå‹•é¸æ“‡GPU
    if args.gpu_id == -2:  # è‡ªå‹•é¸æ“‡æ¨¡å¼
        args.gpu_id = get_available_gpu()
        print(f"è‡ªå‹•é¸æ“‡ GPU: {args.gpu_id}")

    obj_batch = [['capsule'], ['bottle'], ['carpet'], ['leather'], ['pill'],
                 ['transistor'], ['tile'], ['cable'], ['zipper'],
                 ['toothbrush'], ['metal_nut'], ['hazelnut'], ['screw'],
                 ['grid'], ['wood']]

    if int(args.obj_id) == -1:
        obj_list = [
            'capsule', 'bottle', 'carpet', 'leather', 'pill', 'transistor',
            'tile', 'cable', 'zipper', 'toothbrush', 'metal_nut', 'hazelnut',
            'screw', 'grid', 'wood'
        ]
        picked_classes = obj_list
    else:
        picked_classes = obj_batch[int(args.obj_id)]

    # æ ¹æ“šé¸æ“‡çš„GPUåŸ·è¡Œ
    if args.gpu_id == -1:
        # ä½¿ç”¨CPU
        main(picked_classes, args)
    else:
        # ä½¿ç”¨GPU
        with torch.cuda.device(args.gpu_id):
            main(picked_classes, args)